[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Lasse Ishøi, PhD",
    "section": "",
    "text": "Hi, and welcome to my personal webpage!\nI am a clinical researcher with a background in sport science and physiotherapy with a great interest in hip/groin and hamstring injuries, and data analytics.\nI serve as the Head of Sport and Data Science in Football Club Nordsjælland, a Danish premier league football club with associated youth academies in Denmark and Ghana (rated as one of the world’s best academies according to Scouted Football), where I focus on structured data collection and associated analyses to support desicion-making processes. As part of this position, I have developed Power Apps for streamlined data collection, Power BI and R Shiny Dashboards for reporting, and also been involved in developing an SQL database.\nI also work as postdoctoral researcher at the Sports Orthopedic Research Center - Copenhagen (SORC-C) at Hvidovre Hospital; an International Olympic Committee (IOC) research center centered around prevention, diagnostics and treatment of musculoskeletal problems.\nI completed my PhD in 2022 at SORC-C entitled “Femoroacetabular Impingement Syndrome: Patient Acceptable Symptom State, Return t Sport, and Hip Muscle Strength After Hip Arthroscopy”."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\nlibrary(scholar)\n\n\n id &lt;- \"Vkg8k1sAAAAJ&hl\"\n \n citations &lt;- get_citation_history(id)\n \n \n \n sum(citations$cites)\n\n[1] 1472\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "index.html#teaching-focus",
    "href": "index.html#teaching-focus",
    "title": "Lasse Ishøi, PhD",
    "section": "Teaching Focus",
    "text": "Teaching Focus"
  },
  {
    "objectID": "index.html#current-projects",
    "href": "index.html#current-projects",
    "title": "Lasse Ishøi",
    "section": "Current Projects",
    "text": "Current Projects\n\nMigrating teaching site from Hugo/blogdown to Quarto\nDesigning bootstrapped regression modules with rsample\nEnhancing teaching videos with Premiere Elements"
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Lasse Ishøi",
    "section": "",
    "text": "Lasse is a sport scientist and educator specializing in Bayesian modeling, reproducible workflows, and DAX analytics. He teaches data science for sport applications using R and Quarto, and builds annotated modules to empower learners."
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "My Blog",
    "section": "",
    "text": "In Situ Acceleration-Speed Profile\n\n\n\nSport Science\n\nSprint\n\nR\n\n\n\nsdsadasdasd\n\n\n\nLasse Ishøi\n\n\nOct 13, 2025\n\n\n\n\n\n\nNo matching items\n Back to top"
  },
  {
    "objectID": "posts/2025-13-10-speed-acceleration-package/index.html",
    "href": "posts/2025-13-10-speed-acceleration-package/index.html",
    "title": "In Situ Acceleration-Speed Profile",
    "section": "",
    "text": "Introduction\nThe In Situ Acceleration-Speed (AS) Profile has gained increasing popularity since introduced by JB Morin and team in 2021. Briefly described, the AS profile is in-game recording of the maximal acceleration and speed capabilities based on instantaneous acceleration and speed data from GPS or equivalent tracking devices from multiple training sessions/games. For an in depth overview of the concept, a good place to start is the blogpost or Presentation by JB Morin and/or the following scientific papers:\n\nIndividual acceleration-speed profile in-situ: A proof of concept in professional football players\nReliability of individual acceleration-speed profile in-situ in elite youth soccer players\nMinimal Number of Events Required for Acceleration-Speed Profiling in Elite Women’s Soccer\n\n\n\nThe simple but tedious way of calculating the AS Profile\nOnly a few GPS providers allow for the calculation of the AS profile in the cloud using proprietary software, so being able to calculate the AS profile yourself may be valuable. Luckily, this can be simply done by using the web application by Yann Le Mat - all it takes is to upload the raw GPS data as a .csv file.\nAlthough this seems easy enough, several training sessions are needed for a valid and reliable estimation of the AS profile (see linked papers above), thus calculating the AS profile for a whole squad can easily mean that 100-200 .csv files need to be downloaded (typically 1 file per player per session with 30.000-100.000 rows depending on the session duration). This quickly becomes very tedious work!\n\n\nThe easier way using the CatapultR Package and R Studio\nAnother, and much easier, method (at least if working with Catapult GPS data) is to leverage the power of R and the catapultR package which serves as a wrapper for the Catapult API. This essentially means that no manual downloading of .csv files are needed. Below, I will show you step by step how you can use the CatapultR package to download the raw GPS 10Hz data.\nTo get started in R Studio, I load the following packages:\n\nlibrary(catapultR)\nlibrary(tidyverse)\nlibrary(lubridate)\n\n…and set a few placeholder variables and the API connection:\n\n#Set player name, and date range for the data of interest\nplayerName &lt;- name\nstartDate &lt;- startdate\nendDate &lt;- enddate\n\n\n#Get API Access\nsToken &lt;- stoken\nsRegion &lt;- sregion\n\n\n#Setup API connection\ntoken &lt;- ofCloudCreateToken(sToken = sToken,  sRegion = sRegion)\n\nThe next code chunks uses several functions from the CatapultR package to retrieve the raw 10HZ sensor data via the API connection. I use the three parameters (defined above) playerName, startDate, and endDate to specify the data of interest.\nI first extract a list of athletes, format the start and end dates, and extract a list of activities in the specified period:\n\n# Get a list of athletes connected to the Token user\nathletes &lt;- ofCloudGetAthletes(token)\n\n# Use the playerName to identify the associated athlete id\nathletes$player_name &lt;- paste(athletes$first_name, athletes$last_name)\nathleteID &lt;- athletes$id[athletes$player_name==playerName]\n\n# Get a list activities from the specified period\nfrom &lt;- as.integer(as.POSIXct(as.Date(startDate, format=\"%d-%m-%Y\")))\nto &lt;- as.integer(as.POSIXct(as.Date(endDate, format=\"%d-%m-%Y\")))\nactivities &lt;- ofCloudGetActivities(token, from = from, to = to)\n\nI then create a for loop to loop over the list of activities, and extract activities where the player of interest is present:\n\n# Loop over the activities for the specific athlete to get the 10Hz raw data\n# Create output variable as a list using the vector function with length equal to number of activities\nrawData &lt;- vector(\"list\", nrow(activities))\n\n\n# For loop using the ofCloudGetActivitySensorData function which takes the athleteID and an activity as arguments. \n#\"Try\" function suppresses an error in the for loop if the athlete is not part of an activity.\nfor (i in seq_along(activities)) {try(\nrawData[[i]] &lt;- ofCloudGetActivitySensorData(\n  token,\n  athlete_id = athleteID,\n  activity_id = activities$id[[i]],\n  parameters = c(\"ts\", \n                 \"cs\", \n                 \"lat\", \n                 \"long\", \n                 \"xy\", \n                 \"o\", \n                 \"v\", \n                 \"rv\", \n                 \"a\", \n                 \"hr\", \n                 \"pl\", \n                 \"sl\", \n                 \"mp\", \n                 \"pq\", \n                 \"ref\", \n                 \"hdop\")), \n  silent = TRUE)\n}\n\nNow that I have the raw 10Hz sensor data for each activity extracted and in a list, I use the “map” (that applies a function on a list) and “unnest” functions to unnest the gps variables for each activity:\n\n# Map function to unnest the data (gps variables) column across the list. \n# \"Possibly\" function secures that the unnest function does not stop due to error\n\nrawData_list &lt;- rawData %&gt;%\n                            map(possibly(~unnest(data = ., cols = \"data\"), NULL)) %&gt;%\n# Delete empty lists - these are activities where the player of interest has not participated\n                            compact()\n\nAnd finally, I rename the columns and create a few additional time columns (timestamp, seconds, elapsed_time):\n\n# Mutate a time column using lubridate based on ts (epoch), and rename columns\nrawData_list &lt;-  rawData_list %&gt;% map(~mutate(.data = ., timestamp = as_datetime(.$ts),\n                                                          seconds = round(cs/100, 1),\n                                                          elapsed_time = (row_number()-1)/10)) %&gt;%\n                                  map(~rename(.data = ., latitude = lat,\n                                              longitude = long,\n                                              position_x = x,\n                                              position_y = y,\n                                              velocity = v,\n                                              velocity_raw = rv,\n                                              acceleration = a,\n                                              total_distance = o,\n                                              heart_rate = hr,\n                                              player_load = pl,\n                                              smoothed_load = sl,\n                                              metabolic_power = mp,\n                                              positional_quality = pq,\n                                              number_satelites = ref))\n\nTo make it easier going forward I wrap it all in a function:\n\nget_raw_data &lt;- function(name, startdate, enddate, stoken, sregion) {\n\n#Add the variables to extract the data of interest\nplayerName &lt;- name\nstartDate &lt;- startdate\nendDate &lt;- enddate\n\n#Add the variables for the API connection\nsToken &lt;- stoken\nsRegion &lt;- sregion\n\ntoken &lt;- ofCloudCreateToken(sToken = sToken,  sRegion = sRegion)\n\n#And just copy-paste the above code chunks in here\n\n...\n\n}\n\nThe final step I need to solve before I can use the function is to identify the sToken and the sRegion (These are text strings used to access your user profile via the API, and can be found in the Catapult Cloud). With that in place, I am ready to collect some raw 10 Hz data by simply adding the parameters to the function:\n\n#I want to get data from Player A in date range 5th to 10th January 2024\ndata &lt;- get_raw_data(name = \"Player A\", \n                            startdate = \"05-01-2024\", \n                            enddate = \"10-01-2024\", \n                            stoken = \"xxx\", \n                            sregion = \"xxx\")\n\nThe data comes in a list format, with each list representing an activity. For this example, I get 4 activities (training sessions only), which is on the low end for obtaining a reliable AS profile, but that is not the main focus for now.\nThe raw data looks like this with each row representing 0.1 seconds (sampling rate of 10 Hz) (only a few columns are selected):\n\n\n\n\n\n\n\n\n\n\n\n\n\nathlete_first_name\nvelocity\nvelocity_raw\nacceleration\nseconds\nelapsed_time\n\n\n\n\nPlayer\nNA\n0.6499864\nNA\n0.0\n6501.0\n\n\nPlayer\nNA\n0.6499864\nNA\n0.1\n6501.1\n\n\nPlayer\nNA\n0.6499864\nNA\n0.2\n6501.2\n\n\nPlayer\nNA\n0.6499864\nNA\n0.3\n6501.3\n\n\nPlayer\nNA\n0.6499864\nNA\n0.4\n6501.4\n\n\nPlayer\nNA\n0.6499864\nNA\n0.5\n6501.5\n\n\nPlayer\nNA\n0.6499864\nNA\n0.6\n6501.6\n\n\nPlayer\nNA\n0.6499864\nNA\n0.7\n6501.7\n\n\nPlayer\nNA\n0.6499864\nNA\n0.8\n6501.8\n\n\nPlayer\nNA\n0.6499864\nNA\n0.9\n6501.9\n\n\n\n\n\n\n\nDealing with API limits\nBecause the function tries to pull raw 10Hz GPS data through the Catapult API, it calls a large amount of data. Depending on the date range (determined by startDate and endDate parameters), you may experience that you get fewer than expected activities or simply empty activities. This may even happen if the date range spans 5 days. I reckon this may be due to the API limit of the call. The obvious way to solve this is to repeat the function with different start and end dates until the desired days are covered, and then bind the outputs into a single data frame. However, in the long run, this is not very feasible. A cleaner method is to use the Purr package from the Tidyverse collection to loop over the get_raw_data function using consecutive dates as inputs. In this way, the function runs in small batches and thus overcome the potential issue of reaching the API limit. This is potentially very powerful, so please use it with respect as there is a reason for the API limit set by Catapult. In this specific case, using raw data for the Acceleration-Speed profile, a date range of 7-10 days should be sufficient.\n\n# I first define the date range and sequence of start dates - I use the seq function to \n# create consecutive days within the range, and minus by 1, \n# since the end date will by the start date + 1\nstart_dates_list &lt;- seq(dmy(\"05-01-2024\"), dmy(\"10-01-2024\") - 1, by = \"days\")\nend_dates_list &lt;- start_dates_list + 1\n\n\n# The trick now is to use the map2 function, to loop over combinations of start and end dates\n# applying those to the get_raw_data function\ndata &lt;- map2(start_dates_list, end_dates_list, ~ get_raw_data(\n  name = \"Player A\",\n  startdate = format(.x, \"%d-%m-%Y\"),\n  enddate = format(.y, \"%d-%m-%Y\"),\n  stoken = stoken,\n  sregion = sregion\n))\n\nEssentially what happens in the code is that the get_raw_data function runs five times, starting with a start date of “05-01-2024” and an end date of “06-01-2024”, then a start date of “06-01-2024” and an end date of “07-01-2024”, etc., until having covered the entire date range.\n\nPreparation of the raw data\nFor the preparation of the speed acceleration data, I use the Signal package and a butterworth filter as outlined in Clavel et al., 2023.\nI use the filter on the raw velocity data, as opposed to the velocity data already filtered by Catapult, to secure consistency.\n\nlibrary(signal)\n\n#Set filter details\nbf4 &lt;- butter(2, 0.10, type=\"low\")\n\n#Apply filter\nrawData_list &lt;- data %&gt;%\n                    #Delete NA's\n                    map(~na.omit(.)) %&gt;%\n                    #Apply filter on raw velocity data across lists\n                    map(~mutate(.data = ., velocity_raw_bw = filtfilt(bf4, .$velocity_raw)))\n\nI then calculate instantaneous acceleration based on the filtered velocity data. There are a few ways this can be done. I use a running linear regression with a window of 3. This means that three consecutive velocity observations are used to create a linear regression with the slope of the being the acceleration. It makes the calculation of acceleration a little less sensitive to outliers in velocity data.\n\n library(runner)\n library(useful)\n\n\n rawData_list_acc &lt;- rawData_list %&gt;%\n                     map(~mutate(.data = .,\n                                 reg_acc = runner(x = .,\n                                                  k = 3,\n                                                  na_pad = FALSE,\n                                                  f = function(x){\n                                                  model &lt;- lm(velocity_raw_bw ~ elapsed_time,\n                                                  data = x)\n                                   coefficients(model)[2]})))\n\n # I shift the calculated acceleration column 1 row up since the first value is NA\n rawData_list_shifted &lt;- rawData_list_acc %&gt;%\n                                      map(~shift.column(data = .,\n                                                        columns = \"reg_acc\",\n                                                        newNames = \"acc\",\n                                                        up = TRUE, len = 1))\n\n # Finally, I bind the lists into a single data frame\n all_data &lt;- rawData_list_shifted %&gt;%\n                             bind_rows()\n\n\n\nInspection of the data\nTo quickly check that the velocity and acceleration traces make sense, I visualize a snapshot of the traces. It seems to fit (acceleration is the red line).\n\n\n\n\n\n\n\n\n\nThe second inspection is the scatter plot with acceleration on the y-axis and velocity on the x-axis. This depicts the entire spectrum of instantaneous acceleration-velocity and gives you a good impression on the data quality. E.g. if you see high accelerations towards high velocities you should be concerned. Also the maximum acceleration should typically be found at a velocity of less then 3 m/s.\n\n all_data %&gt;%\n  ggplot(aes(x = velocity_raw_bw, y = acc)) +\n        geom_point(size = 0.2) +\n        ylim(0,NA) +\n        geom_vline(xintercept = 3, color = \"red\") +\n        theme_pubclean() +\n        xlab(\"Velocity (m/s)\") +\n        ylab(\"Acceleration (m/s-2)\")\n\n\n\n\n\n\n\n\nThe data looks good, and I proceed to the final step. I use the InSituASProfile package, which I have developed. I first prepare the data using the prepare_data function, which also creates an initial regression line, so that one can decide if it is feasible to proceed to the final calculation. In this case, points are located very close to the regression line with an r-square value of 0.98 and I proceed to the final model model/calculation.\n\nlibrary(InSituASProfile)\n\n# I rename the column as the InSituASProfile package need a \"acc\" and \"speed\" column\n all_data &lt;- all_data %&gt;%\n            rename(speed = velocity_raw_bw)\n \n \n# Prepare data and inition plot\nInSituASProfile::prepare_data(all_data, print_plot = TRUE)\n\n\n\n\n\n\n\n\nThe final model can be computed using either the 95 CI or Turkey boxplot method for outlier removal. The 95 CI method is the original method described in Individual acceleration-speed profile in-situ: A proof of concept in professional football players. This method initially fits a regression model, removes points outside of the 95 CI limits, before fitting the final model. The box plot method has recently been described in Comparison of acceleration-speed profiles from training and competition to individual maximal sprint efforts. This method uses the top 2 percent of accelerations for each velocity bin (0.1 m/s), constructs a box plot for each bin, and then removes points outside of the IQR * 1. Subsequently, the final regression model is fitted. By default, InSituASProfile::get_AS_Profile uses the 95% CI outlier detection, but if you want to use the box plot method just set ci_outlier_detection = FALSE.\n\n#Using the 95% CI method\nInSituASProfile::get_AS_Profile(print_plot_regression_line = FALSE, \n                                print_AS_plot = TRUE, \n                                ci_outlier_detection = TRUE)\n\n\n\n\n\n\n\n#Using the box plot method\nInSituASProfile::get_AS_Profile(print_plot_regression_line = FALSE, \n                                print_AS_plot = TRUE, \n                                ci_outlier_detection = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "index.html#teaching-focu",
    "href": "index.html#teaching-focu",
    "title": "Lasse Ishøi, PhD",
    "section": "Teaching Focu",
    "text": "Teaching Focu"
  },
  {
    "objectID": "index.html#main-competencies",
    "href": "index.html#main-competencies",
    "title": "Lasse Ishøi, PhD",
    "section": "Main Competencies",
    "text": "Main Competencies"
  }
]